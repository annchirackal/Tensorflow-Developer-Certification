{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSpqkIJsnlJpZikXLmjJ8Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annchirackal/Tensorflow-Developer-Certification/blob/TF_Transfer_Learning/12_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####What is transfer learning?<br>\n",
        "\n",
        "we can leverage an existing nueral network architecture proven to work on similar problems which is already learned patterns from dataset  similar  to our own.\n",
        "\n"
      ],
      "metadata": {
        "id": "DiCd_cqyfLEL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data:\n",
        "we are going to use only 10 percent data, this would help us to understand the powe of transfer learning."
      ],
      "metadata": {
        "id": "vBYco3CrisZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import datetime"
      ],
      "metadata": {
        "id": "EJBuG3MjjlXQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Global variables\n",
        "IMAGE_SHAPE=(224,224)\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=5"
      ],
      "metadata": {
        "id": "fkd5OTsVmpuf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-MEP_EHuFzu4"
      },
      "outputs": [],
      "source": [
        " !wget -q https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the loaded file\n",
        "zip_ref=zipfile.ZipFile(\"/content/10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "tcZyd4uljVj9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  #lets inspect the directory\n",
        "for dirpath,dirnames,filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "\n",
        "    print(f\"{len(filenames)} files and  {len(dirnames)} in directory {dirpath}\")\n"
      ],
      "metadata": {
        "id": "-4beZA9Mj13X",
        "outputId": "a7843c2f-b4da-49a2-c5be-d789b41bf821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 files and  2 in directory 10_food_classes_10_percent\n",
            "0 files and  10 in directory 10_food_classes_10_percent/train\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/chicken_curry\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/pizza\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/hamburger\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/sushi\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/chicken_wings\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/grilled_salmon\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/fried_rice\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/steak\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/ice_cream\n",
            "75 files and  0 in directory 10_food_classes_10_percent/train/ramen\n",
            "0 files and  10 in directory 10_food_classes_10_percent/test\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/chicken_curry\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/pizza\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/hamburger\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/sushi\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/chicken_wings\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/grilled_salmon\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/fried_rice\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/steak\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/ice_cream\n",
            "250 files and  0 in directory 10_food_classes_10_percent/test/ramen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 75 images of each class for traning and 250 from each class for validation"
      ],
      "metadata": {
        "id": "xDYxfpBUlovW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #### set the path variables\n",
        "\n",
        "train_dir=\"/content/10_food_classes_10_percent/train\"\n",
        "test_dir=\"/content/10_food_classes_10_percent/test\"\n",
        "\n",
        "train_data_gen=ImageDataGenerator(rescale=1./255,)\n",
        "test_data_gen=ImageDataGenerator(rescale=1./255,)\n",
        "print(\"Traning Images:\")\n",
        "train_data=train_data_gen.flow_from_directory(train_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode=\"categorical\")\n",
        "print(\"Testing Images:\")\n",
        "train_data=train_data_gen.flow_from_directory(test_dir,\n",
        "                                              target_size=IMAGE_SHAPE,\n",
        "                                              batch_size=BATCH_SIZE,\n",
        "                                              class_mode=\"categorical\")\n"
      ],
      "metadata": {
        "id": "8MSbJFBilnli",
        "outputId": "fa819c20-34cf-48eb-c43a-d42712c1e5c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traning Images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing Images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks are extra functionality you can add to your model to be performed during or after training.Some of the most popular call backs are\n",
        "- Model check point with the ModelCheckpoint callbacks.\n",
        "- Tracking experiment with tensor board callbacks.\n",
        "- Stopping a model from traning with EarlyStopping callbacks."
      ],
      "metadata": {
        "id": "lgLZmmCEGzF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a tensorboard callbacks\n",
        "\n",
        "def create_tensorboard_callbacks(dirname,experiment_name):\n",
        "  log_dir=dirname+\"/\"+experiment_name+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=log_dir,)\n",
        "  print(f\"Saving TensorBorad log files to {log_dir} \")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "Ck2geNTUmP7e"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Models using Tensorflow hub<br>\n",
        "\n",
        "In previous notebooks we have created custom models from scratch. Here we are creating a model by using layers from pretrained models availble in tensor hub.\n"
      ],
      "metadata": {
        "id": "HfsRi1knJ4Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpdJZxLSKpdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}